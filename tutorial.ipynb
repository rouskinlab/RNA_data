{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import os, sys\n",
                "\n",
                "import envbash\n",
                "envbash.load.load_envbash('./env')\n",
                "\n",
                "\n",
                "sys.path.append('/Users/yvesmartin/src/rouskinhf')\n",
                "from rouskinhf import convert, upload_dataset, get_dataset\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create a datafolder from local files\n",
                "\n",
                "These methods will allow you to process your data and create a datafolder from it. The accepted formats are:\n",
                "- DREEM output\n",
                "- fasta\n",
                "- set of CTs\n",
                "- already formatted json + info.json\n",
                "\n",
                "**Make sure to change the paths to your own paths!**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### From SEISMIC-json format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Parsing dreem output file: 100%|██████████| 13/13 [00:01<00:00,  8.71it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Over a total of 13 datapoints, there are:\n",
                        "### OUTPUT\n",
                        "- 10 valid datapoints\n",
                        "### MODIFIED\n",
                        "- 0 multiple sequences with the same reference (renamed reference)\n",
                        "### FILTERED OUT\n",
                        "- 1 invalid datapoints (ex: sequence with non-regular characters)\n",
                        "- 0 datapoints with bad structures\n",
                        "- 0 duplicate sequences with the same structure / dms\n",
                        "- 0 duplicate sequences with different structure / dms\n",
                        "- 2 datapoints removed because of low AUROC (<0.5)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "%reload_ext autoreload\n",
                "%autoreload 2\n",
                "# Show all arguments\n",
                "data = convert(format='seismic', \n",
                "              file_or_folder='data/input_files_for_testing/test_dreem_output.json',\n",
                "              name='seismic_output',\n",
                "              path_out='data/testing',\n",
                "              predict_structure=True,\n",
                "              filter=True,\n",
                "              min_AUROC=0.5,   \n",
                "              verbose=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### From a data.json file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Parsing json file: 100%|██████████| 10/10 [00:00<00:00, 19887.64it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Over a total of 10 datapoints, there are:\n",
                        "### OUTPUT\n",
                        "- 10 valid datapoints\n",
                        "### MODIFIED\n",
                        "- 0 multiple sequences with the same reference (renamed reference)\n",
                        "### FILTERED OUT\n",
                        "- 0 invalid datapoints (ex: sequence with non-regular characters)\n",
                        "- 0 datapoints with bad structures\n",
                        "- 0 duplicate sequences with the same structure / dms\n",
                        "- 0 duplicate sequences with different structure / dms\n",
                        "- 0 datapoints removed because of low AUROC (<0.5)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "data = convert(format='json', \n",
                "              file_or_folder='data/input_files_for_testing/data.json',\n",
                "              path_out='data/testing',\n",
                "              predict_structure=True,\n",
                "              filter=True,   \n",
                "              min_AUROC=0.5,\n",
                "              verbose=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### From a list of CT files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Parsing ct files: 100%|██████████| 5/5 [00:00<00:00, 1483.66it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Over a total of 5 datapoints, there are:\n",
                        "### OUTPUT\n",
                        "- 2 valid datapoints\n",
                        "### MODIFIED\n",
                        "- 0 multiple sequences with the same reference (renamed reference)\n",
                        "### FILTERED OUT\n",
                        "- 1 invalid datapoints (ex: sequence with non-regular characters)\n",
                        "- 0 datapoints with bad structures\n",
                        "- 1 duplicate sequences\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "%reload_ext autoreload\n",
                "%autoreload 2\n",
                "data = convert(format='ct', \n",
                "              file_or_folder='data/input_files_for_testing/test_ct_files',\n",
                "              path_out='data/testing',\n",
                "              predict_structure=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "### From fasta"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Parsing fasta file: 100%|██████████| 5/5 [00:00<00:00, 28.37it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Over a total of 5 datapoints, there are:\n",
                        "### OUTPUT\n",
                        "- 3 valid datapoints\n",
                        "### MODIFIED\n",
                        "- 1 multiple sequences with the same reference (renamed reference)\n",
                        "### FILTERED OUT\n",
                        "- 1 invalid datapoints (ex: sequence with non-regular characters)\n",
                        "- 0 datapoints with bad structures\n",
                        "- 0 duplicate sequences\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "data = convert(format='fasta', \n",
                "              file_or_folder='data/input_files_for_testing/test_sequences.fasta',\n",
                "              path_out='data/testing',\n",
                "              predict_structure=True,\n",
                "              filter=True,   \n",
                "              verbose=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Push a local datafolder to Hugging Face"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Find more arguments here: https://huggingface.co/docs/huggingface_hub/guides/upload#upload-a-folder\n",
                "upload_dataset(\n",
                "    datapath='data/testing/seismic_output/data.json', \n",
                "    exist_ok=True,\n",
                "    commit_message='test upload',\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Check that the datafolder is on Hugging Face\n",
                "\n",
                "Take a look at https://huggingface.co/rouskinlab\n",
                "\n",
                "# Download data from HuggingFace"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e003d1668f624eb38e7e72ec74b3b219",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "data = get_dataset('seismic_output', force_download=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "dl",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
